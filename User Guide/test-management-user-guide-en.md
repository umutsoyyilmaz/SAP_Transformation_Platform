# ProjektCoPilot â€” Test Management System
## User Guide v1.0

---

**Product:** ProjektCoPilot â€” Test Management System
**Version:** 1.0
**Date:** 2026-02-10
**Target Audience:** Test Lead, Module Lead, Facilitator, BPO, Tester, PM
**Related Documents:** Test Management FS/TS v1.0, Explore Phase FS/TS v1.1

---

## Table of Contents

1. [Introduction and Overview](#1-introduction-and-overview)
2. [System Access and Roles](#2-system-access-and-roles)
3. [Module T1: Test Plan & Strategy](#3-module-t1-test-plan--strategy)
4. [Module T2: Test Suite Manager](#4-module-t2-test-suite-manager)
5. [Module T3: Test Execution](#5-module-t3-test-execution)
6. [Module T4: Defect Tracker](#6-module-t4-defect-tracker)
7. [Module T5: Test Dashboard](#7-module-t5-test-dashboard)
8. [Module T6: Traceability Matrix](#8-module-t6-traceability-matrix)
9. [Transitioning from Explore Phase to Testing](#9-transitioning-from-explore-phase-to-testing)
10. [Cloud ALM Synchronization](#10-cloud-alm-synchronization)
11. [Frequently Asked Questions](#11-frequently-asked-questions)
12. [Abbreviations and Glossary](#12-abbreviations-and-glossary)

---

## 1. Introduction and Overview

### 1.1 Who Is This Guide For?

This guide is intended for all project team members who will use the Test Management System within the ProjektCoPilot platform. Use the table below to identify which sections to prioritize based on your role:

| Your Role | Priority Sections |
|-----------|------------------|
| **Test Lead** | All sections â€” especially T1, T4, T5 |
| **Module Lead** | T2 (your area), T3 (execution), T4 (defects) |
| **BPO (Business Process Owner)** | T3 (UAT execution), T4 (defect review), T6 (traceability) |
| **Tester** | T3 (execution), T4 (defect creation) |
| **PM (Program Manager)** | T1 (strategy), T5 (dashboard), T6 (traceability) |
| **Facilitator / Consultant** | T2 (test case authoring), T3 (execution) |

### 1.2 What Is the Test Management System?

The Test Management System is the module that ensures all requirements, WRICEF/Config items, and business processes produced during the Explore Phase of an SAP S/4HANA project are systematically tested.

The system covers 6 test levels:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      6 TEST LEVELS                                â”‚
â”‚                                                                   â”‚
â”‚  1. UNIT TEST         Individual object validation (WRICEF/Config)â”‚
â”‚  2. STRING TEST       Intra-module process chain                  â”‚
â”‚  3. SIT               Cross-module end-to-end integration         â”‚
â”‚  4. UAT               Business user acceptance testing            â”‚
â”‚  5. REGRESSION         Safeguarding existing processes            â”‚
â”‚  6. PERFORMANCE        System behavior under load                 â”‚
â”‚                                                                   â”‚
â”‚  + DEFECT MANAGEMENT (cross-cutting across all levels)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Test Management and Explore Phase Relationship

Test Management is the direct continuation of the Explore Phase. Every output created in Explore becomes an input for the testing process:

```
WHAT DID YOU DO IN EXPLORE?                WHAT HAPPENS IN TESTING?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Made a fit decision in a workshop     â†’    SIT and UAT scenarios are generated
Created a requirement                 â†’    Test cases are linked to it
Defined a WRICEF item                 â†’    Unit tests are auto-generated
Defined a Config item                 â†’    Unit tests are auto-generated
Drew an E2E process flow              â†’    SIT scenario tests this flow
Approved a process as BPO             â†’    You will retest it in UAT
```

### 1.4 Navigation

Access the Test Management System by clicking **Test Mgmt** in the left sidebar. It contains 6 sub-screens:

```
Test Mgmt
  â”œâ”€â”€ T1: Plan & Strategy       (test plan and strategy)
  â”œâ”€â”€ T2: Suite Manager          (test case management)
  â”œâ”€â”€ T3: Execution              (test running)
  â”œâ”€â”€ T4: Defect Tracker         (defect tracking)
  â”œâ”€â”€ T5: Dashboard              (KPIs and Go/No-Go)
  â””â”€â”€ T6: Traceability           (traceability matrix)
```

---

## 2. System Access and Roles

### 2.1 Roles and Permissions

The Test Management System introduces the **Test Lead** role in addition to the 7 existing Explore Phase roles. The table below shows what each role can and cannot do:

| Action | PM | Module Lead | Test Lead | BPO | Tester | Facilitator | Tech Lead |
|--------|:--:|:----------:|:---------:|:---:|:------:|:----------:|:---------:|
| Create/edit test plan | âœ“ | â€” | âœ“ | â€” | â€” | â€” | â€” |
| Approve test plan | âœ“ | â€” | â€” | â€” | â€” | â€” | â€” |
| Create test suite | âœ“ | âœ“* | âœ“ | â€” | â€” | â€” | â€” |
| Create/edit test case | âœ“ | âœ“ | âœ“ | â€” | âœ“ | âœ“ | âœ“ |
| Approve test case | âœ“ | âœ“* | âœ“ | â€” | â€” | â€” | â€” |
| Execute test | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ |
| Create defect | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ |
| Assign defect | âœ“ | âœ“* | âœ“ | â€” | â€” | â€” | â€” |
| Resolve defect | âœ“ | âœ“ | â€” | â€” | â€” | âœ“ | âœ“ |
| Retest defect | âœ“ | âœ“ | âœ“ | â€” | âœ“ | â€” | â€” |
| Close defect | âœ“ | âœ“ | âœ“ | â€” | â€” | â€” | â€” |
| Provide UAT sign-off | âœ“ | â€” | â€” | âœ“ | â€” | â€” | â€” |
| Export dashboard | âœ“ | âœ“ | âœ“ | âœ“ | â€” | â€” | â€” |

*\* Module Lead: within their own process area only*

### 2.2 Who Uses Which Screen and When

**Test Lead â€” Daily routine:**
1. T5 Dashboard â†’ overall status check, Go/No-Go red items
2. T4 Defect Tracker â†’ triage new defects (severity, priority, assignment)
3. T3 Execution â†’ progress of ongoing test runs
4. T1 Plan â†’ update the test calendar

**Module Lead (e.g., FI Lead) â€” Daily routine:**
1. T4 â†’ defects assigned to their area
2. T2 â†’ test case approval status
3. T3 â†’ test execution progress in their area

**BPO â€” During UAT period:**
1. T3 â†’ run UAT scenarios
2. T4 â†’ log defects for issues found
3. UAT sign-off â†’ provide the "I accept this process" approval

**Tester â€” Daily routine:**
1. T3 â†’ run assigned test cases
2. T4 â†’ create defects for failed steps
3. T4 â†’ retest resolved defects

---

## 3. Module T1: Test Plan & Strategy

### 3.1 What Is Done Here?

The Test Plan is the central document for the project's test strategy. A single test plan is created per project. The test plan defines:

- Which test levels will be applied?
- What are the entry and exit criteria for each level?
- Which environments (DEV, QAS, PRD) will be used?
- What is the test calendar?
- Roles and responsibilities

### 3.2 Creating a Test Plan

**Path:** Test Mgmt â†’ T1: Plan & Strategy â†’ "+ Create Test Plan"

**Steps:**

1. **Enter plan information:**
   - Plan name (e.g., "ArÃ§elik S/4HANA Test Plan")
   - Version (e.g., "1.0")

2. **Write the strategy document:** A Markdown editor opens in the Strategy tab. Document your test approach, risks, tools, and out-of-scope areas here.

3. **Fill in the environment matrix:** In the Environments tab, specify which environment will be used for each test level:

   | Test Level | Environment | Notes |
   |-----------|-------------|-------|
   | Unit Test | DEV | Developer's own environment |
   | String Test | QAS | After transport |
   | SIT | QAS | Integration testing |
   | UAT | QAS | Business user environment |
   | Regression | QAS | Can be run automatically |
   | Performance | QAS (or dedicated) | Load testing environment |

4. **Define entry/exit criteria:** In the Criteria tab, specify conditions for each level. The system pre-fills default criteria, which you can customize as needed.

5. **Submit for approval:** Click "Submit for Approval." When the PM approves, the plan moves to `approved` status.

### 3.3 Test Calendar

The Calendar tab shows a timeline of test cycles. This is a Gantt-like view:

```
              Week 1    Week 2    Week 3    Week 4    Week 5    Week 6
Unit Test     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
String Test              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
SIT                               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
UAT                                          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Regression                                              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Performance                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

Each bar represents a test cycle (test_cycle). Click a bar to navigate to that cycle's detail.

### 3.4 Creating a Test Cycle

**Path:** T1: Plan â†’ "+ Create Cycle"

A test cycle is the execution window for a specific test level within a specific time period. For example, "Wave 1 â€” SIT Cycle 1."

**Fields:**
- **Code:** Auto-assigned (TC-001, TC-002, ...)
- **Name:** Descriptive name (e.g., "Wave 1 â€” SIT Cycle 1")
- **Test level:** Unit, String, SIT, UAT, Regression, Performance
- **Wave:** Which wave it belongs to (1, 2, 3, 4)
- **Planned start/end:** Calendar selection
- **Assigned suites:** Select the test suites to be run in this cycle

**Starting a cycle:**
When you click "Start," the system checks entry criteria. If criteria are not met, a warning is shown. You can override with `force=true`, but this is logged.

---

## 4. Module T2: Test Suite Manager

### 4.1 Concepts

The building blocks of test management follow this hierarchy:

```
Test Plan (1 per project)
  â””â”€â”€ Test Suite (level + area-based grouping)
        â””â”€â”€ Test Case (individual test scenario)
              â””â”€â”€ Test Step (sequential test steps)
```

**Test Suite** = a logical grouping of test cases. Each suite belongs to a single test level.

**Example suites:**
- TS-UT-001: "FI â€” Unit Tests â€” Financial Closing"
- TS-SIT-003: "O2C End-to-End â€” Order to Cash"
- TS-UAT-008: "SD â€” Happy Path â€” Domestic Sales"
- TS-REG-002: "MM â€” Regression Suite â€” Procurement"

### 4.2 Creating a Suite

**Path:** Test Mgmt â†’ T2: Suite Manager

The top of the screen has 6 tabs â€” one for each test level:

```
[Unit] [String] [SIT] [UAT] [Regression] [Performance]
```

Click the desired level, then press "+ Create Suite."

**Fields:**
- **Name:** Descriptive (e.g., "FI â€” Unit Tests â€” GL Posting")
- **Test level:** Auto-filled from the selected tab
- **Process area:** FI, SD, MM, PP, QM, ... (dropdown)
- **Wave:** 1, 2, 3, 4
- **Scope item:** Link to an L3 scope item from Explore Phase (optional)
- **E2E scenario:** O2C, P2P, R2R, H2R, ... (for SIT and UAT)
- **Risk level:** Critical, High, Medium, Low (for regression)
- **Owner:** Suite owner (person)

### 4.3 Creating a Test Case â€” Manual Method

**Path:** T2 â†’ relevant suite â†’ "+ Create Test Case"

**Fields:**

| Field | Description | Required |
|-------|-------------|----------|
| Title | Short description of the test case | Yes |
| Description | Detailed description | No |
| Priority | P1 (highest) â€” P4 (lowest) | Yes (default: P2) |
| Preconditions | What must be in place before testing? | No |
| Test data | What data will be used? | No |
| Estimated duration | Execution time (minutes) | No |
| UAT category | UAT only: Happy Path, Exception, Negative, Day-in-Life, Period-End | Yes for UAT |
| Regression risk | Regression only: Critical, High, Medium, Low | Yes for Regression |
| Perf. test type | Performance only: Load, Stress, Volume, Endurance, Spike | Yes for Performance |

**Traceability links (critical!):**
- **Requirement:** Which Explore requirement is this linked to?
- **WRICEF Item:** Which WRICEF item is being tested?
- **Config Item:** Which config item is being tested?
- **Process Level:** Which L3/L4 scope item/sub-process is this linked to?

These links are not mandatory but are **strongly recommended**. Missing links appear as gaps in the Traceability Matrix.

### 4.4 Writing Test Steps

After creating a test case, you need to define its steps. For each step:

| # | Field | Description | Example |
|---|-------|-------------|---------|
| 1 | **Action** | What should the tester do? | "Create a sales order using VA01" |
| 2 | **Expected result** | What should happen? | "Order number is generated, status is Open" |
| 3 | **Test data** | What data? | "Customer: 1000001, Material: FG-001, Qty: 100" |
| 4 | **SAP transaction** | T-code | "VA01" |
| 5 | **Module** | If cross-module | "SD" |
| 6 | **Checkpoint?** | Is this a critical validation point? | â˜‘ Yes |

**Tips for writing steps:**
- Keep each step atomic â€” one action, one validation.
- Write expected results precisely â€” not "should work correctly" but "a 10-digit order number should be created with status Open."
- Use the checkpoint flag at integration points (module transitions, interface calls).

### 4.5 Automatic Test Case Generation â€” From Explore Phase

This is one of the system's most powerful features. You can automatically generate test cases from the WRICEF/Config items and process steps defined in the Explore Phase.

#### 4.5.1 Unit Test Generation from WRICEF/Config

**Path:** T2 â†’ Unit tab â†’ relevant suite â†’ "Generate from WRICEF" button

**What happens:**
1. A dialog opens listing the project's WRICEF and Config items.
2. Select the items for which you want to generate unit tests.
3. Click "Generate."
4. The system reads the `unit_test_steps` field from each WRICEF/Config item (this field was populated during the FS/TS writing in the Explore Phase).
5. At least 1 test case is created per item, with steps auto-filled.
6. Test cases are created in `draft` status â€” you need to review and approve them.

**Example:**
```
WRICEF Item: WRICEF-042 (Report â€” GL Trial Balance)
  unit_test_steps:
    1. Run the report (t-code: ZFI_TRIAL)
    2. Apply Company Code filter
    3. Select date range
    4. Verify results â€” balance consistency

    â†’ Auto-generated Test Case: UT-042
      Title: "Unit Test â€” GL Trial Balance Report"
      4 steps auto-filled
      requirement_id, wricef_item_id auto-linked
```

#### 4.5.2 SIT/UAT Generation from Process Steps

**Path:** T2 â†’ SIT or UAT tab â†’ relevant suite â†’ "Generate from Process" button

**What happens:**
1. A dialog opens listing the scope items (L3) from the Explore Phase.
2. Select the scope items for which you want to generate test cases.
3. For UAT, additionally select a category (Happy Path, Exception, Negative, ...).
4. Click "Generate."
5. The system reads the process_steps from the selected scope items' workshops.
6. Steps with a fit decision are sequentially converted into test steps.
7. Cross-module transition points are automatically marked as checkpoints.

**Example:**
```
Scope Item: J58 â€” Domestic Sales (O2C)
  Workshop steps:
    1. Create Sales Order (SD) â€” fit
    2. Check ATP (MM) â€” fit
    3. Create Delivery (SD) â€” fit
    4. Post Goods Issue (WM) â€” partial_fit
    5. Create Invoice (SD) â€” fit
    6. Post Accounting (FI) â€” fit

    â†’ Auto-generated SIT Case: SIT-015
      Title: "SIT â€” O2C â€” Domestic Sales E2E"
      6 steps, module transitions marked as checkpoints
      Step 4 has a "partial_fit" note appended
```

### 4.6 Test Case Statuses

A test case progresses through the following statuses:

```
draft â”€â”€â–º ready â”€â”€â–º approved â”€â”€â–º (deprecated)
  â”‚                    â”‚
  â””â”€â”€ editing          â””â”€â”€ no longer current
```

- **draft:** Newly created, not yet reviewed
- **ready:** Reviewed, ready for approval
- **approved:** Approved, ready to be executed
- **deprecated:** An obsolete case no longer in use

Only test cases in `approved` status can be added to a test run.

### 4.7 Cloning Test Cases

When building a regression suite, you can clone an existing SIT or Unit test case:

**Path:** T2 â†’ relevant test case â†’ "Clone" button

The cloned case is created with a new code (e.g., SIT-015 â†’ REG-008), and all steps are copied. You can then move it to a regression suite and assign a risk level.

---

## 5. Module T3: Test Execution

### 5.1 Test Execution Flow

Test Execution is the screen where test cases are actually run. The flow is:

```
Test Cycle (time window)
  â””â”€â”€ Test Run (a single execution session)
        â””â”€â”€ Test Execution (per-case result)
              â””â”€â”€ Test Step Result (per-step result)
```

### 5.2 Creating a Test Run

**Path:** Test Mgmt â†’ T3: Execution â†’ select a cycle at the top â†’ "+ Create Test Run"

**Fields:**
- **Name:** Descriptive (e.g., "SIT Run 1 â€” O2C Flow")
- **Environment:** DEV, QAS, PRD, Sandbox
- **Test cases:** Select the cases to run (from a suite or individually)

When you click "Create," a `test_execution` record is created for each selected test case (status: `not_run`).

### 5.3 Running a Test â€” Step by Step

**Path:** T3 â†’ relevant run â†’ click the case you want to run â†’ "Run" button

The Execution Workspace opens. This area fills your entire screen and guides you step by step:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Test Case: SIT-015 â€” O2C Domestic Sales E2E               â”‚
â”‚  Suite: TS-SIT-003 | Priority: P1 | Status: In Progress    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Step 1 of 6                                    â± 00:12:34 â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ACTION:                                             â”‚   â”‚
â”‚  â”‚ Create a sales order using VA01                      â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚ EXPECTED RESULT:                                     â”‚   â”‚
â”‚  â”‚ 10-digit order number is created, status: Open       â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚ TEST DATA:                                           â”‚   â”‚
â”‚  â”‚ Customer: 1000001, Material: FG-001, Qty: 100        â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚ T-CODE: VA01  |  MODULE: SD  |  â˜‘ CHECKPOINT         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  ACTUAL RESULT:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ [Enter actual result here]                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  EVIDENCE:                                                  â”‚
â”‚  [ğŸ“ Upload File]  [ğŸ“· Screenshot]                          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ PASS â”‚  â”‚ FAIL â”‚  â”‚ BLOCKED  â”‚  â”‚ SKIPPED  â”‚          â”‚
â”‚  â”‚  âœ“   â”‚  â”‚  âœ—   â”‚  â”‚    âŠ˜     â”‚  â”‚    âŠ     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  [â—„ Previous]                            [Next â–º]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**For each step:**

1. **Perform the action in SAP.**
2. **Enter the actual result** â€” note what happened.
3. **Upload evidence** â€” screenshot or log file (optional but recommended).
4. **Mark the outcome:**
   - **PASS** âœ“ â€” expected result occurred
   - **FAIL** âœ— â€” expected result did not occur â†’ defect creation screen opens
   - **BLOCKED** âŠ˜ â€” test could not be run (environment issue, missing data, etc.)
   - **SKIPPED** âŠ â€” step was skipped (a reason must be provided)

5. **Proceed to the next step.**

### 5.4 Creating a Defect from a Failed Step

When you mark a step as **FAIL**, a quick defect creation form opens at the bottom of the screen:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ› CREATE DEFECT                                       â”‚
â”‚                                                          â”‚
â”‚  Title: [Auto: "SIT-015 Step 3 Fail â€” ..."]             â”‚
â”‚  Description: [Auto: step action + actual result]        â”‚
â”‚  Severity: [S1 â–¾] [S2 â–¾] [S3 â–¾] [S4 â–¾]                 â”‚
â”‚  Priority: [P1 â–¾] [P2 â–¾] [P3 â–¾] [P4 â–¾]                 â”‚
â”‚                                                          â”‚
â”‚  Auto-populated:                                         â”‚
â”‚  â€¢ Test Case: SIT-015                                    â”‚
â”‚  â€¢ Test Step: Step 3                                     â”‚
â”‚  â€¢ Requirement: REQ-042                                  â”‚
â”‚  â€¢ WRICEF Item: WRICEF-023                               â”‚
â”‚  â€¢ Process Area: SD                                      â”‚
â”‚  â€¢ Wave: 1                                               â”‚
â”‚                                                          â”‚
â”‚  [Create Defect]                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The system auto-fills all traceability fields from the test case. You only need to select severity, priority, and add a detailed description.

### 5.5 Execution Result Calculation

When a test case execution is complete, the overall result is calculated as follows:

- All steps PASS â†’ Execution = **PASS**
- Any step FAIL â†’ Execution = **FAIL**
- Any step BLOCKED and no steps FAIL â†’ Execution = **BLOCKED**
- No steps were run â†’ Execution = **NOT_RUN**

### 5.6 Retest

When a defect is resolved (transitions to `retest` status), the associated test case must be re-run.

**Path:** T3 â†’ relevant run â†’ previously FAIL case â†’ "Retest" button

The system creates a new execution record (execution_number: 2, 3, ...). Previous execution results are preserved in the history.

### 5.7 Progress Tracking

The top-right of the Execution screen shows a real-time progress indicator:

```
Pass: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 78%  (156/200)
Fail: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8%   (16/200)
Blocked: â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4%   (8/200)
Not Run: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 10%  (20/200)
```

---

## 6. Module T4: Defect Tracker

### 6.1 What Is a Defect?

A defect is a record of every instance where the expected result did not occur during testing. Defects are independent of test level â€” they can arise in Unit tests, UAT, Performance tests, or any other level.

### 6.2 Defect Lifecycle

Each defect can transition through 9 statuses:

```
    â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚ NEW  â”‚ â† Found during testing
    â””â”€â”€â”¬â”€â”€â”€â”˜
       â”‚ assign
    â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ASSIGNED â”‚ â† Assigned to developer/consultant
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ start_work
    â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚IN PROGRESSâ”‚ â† Fix is being worked on
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ resolve
    â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ RESOLVED â”‚ â† Fix is done, awaiting retest
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ send_to_retest
    â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ RETEST  â”‚ â† Test team is verifying the fix
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      / \
   pass   fail
    /       \
â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚CLOSED â”‚  â”‚REOPENED â”‚â”€â”€â–º Returns to ASSIGNED
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Additional statuses:
â€¢ DEFERRED â€” Not now; added to backlog
â€¢ REJECTED â€” Not a defect (by design, user error)
```

### 6.3 Creating a Defect â€” Manual

**Path:** Test Mgmt â†’ T4: Defect Tracker â†’ "+ Create Defect"

**Required fields:**
- **Title:** Short and descriptive (bad: "There's a bug"; good: "VA01 â€” Pricing condition ZPR1 is not calculated")
- **Description:** Steps to reproduce, expected result, actual result
- **Severity:** S1/S2/S3/S4
- **Priority:** P1/P2/P3/P4

**What does severity mean?**

| Severity | Meaning | Example |
|----------|---------|---------|
| **S1 â€” Showstopper** | System is down, business is stopped | SAP is completely inaccessible |
| **S2 â€” Critical** | Core function is broken, no workaround | Invoice cannot be created, no workaround |
| **S3 â€” Major** | Function is broken but workaround exists | Price is calculated incorrectly, can be fixed manually |
| **S4 â€” Minor** | Minor issue, business is not affected | Typo on screen, report formatting issue |

**What does priority mean?**

| Priority | Meaning | When to fix? |
|----------|---------|-------------|
| **P1 â€” Immediate** | Must be fixed immediately | Within hours |
| **P2 â€” High** | Fix as soon as possible | 1â€“2 business days |
| **P3 â€” Medium** | Fix within the sprint | 3 business days |
| **P4 â€” Low** | Can be added to backlog | By sprint end |

### 6.4 SLA (Service Level Agreement)

When a defect is assigned, the system automatically calculates the resolution deadline:

| Severity + Priority | First Response | Resolution Time | Deadline |
|---------------------|---------------|----------------|----------|
| S1 + P1 | 1 hour | 4 hours | Auto-calculated |
| S2 + P2 | 4 hours | 1 business day | Auto-calculated |
| S3 + P3 | 1 business day | 3 business days | Auto-calculated |
| S4 + P4 | 2 business days | Sprint end | Auto-calculated |

SLA status is shown with colors:
- ğŸŸ¢ **On Track** â€” sufficient time remaining
- ğŸŸ¡ **Warning** â€” time is running out (75% elapsed)
- ğŸ”´ **Breached** â€” deadline exceeded

### 6.5 Defect Views

The Defect Tracker offers two views:

**Table View** â€” ideal for filtering and sorting:

```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ Code â”‚ S  â”‚ P  â”‚ Title                         â”‚ Status   â”‚ Assignee   â”‚ Age  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚DEF-001â”‚ S1 â”‚ P1 â”‚ Invoice cannot be created     â”‚Assigned  â”‚ Ali K.     â”‚ 2d   â”‚
â”‚DEF-002â”‚ S3 â”‚ P3 â”‚ Report format is broken       â”‚In Progr. â”‚ Ayse M.    â”‚ 5d   â”‚
â”‚DEF-003â”‚ S2 â”‚ P2 â”‚ Interface timeout error       â”‚Resolved  â”‚ Mehmet B.  â”‚ 3d   â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

**Kanban View** â€” ideal for flow tracking:

```
 New (3)     â”‚ Assigned (5) â”‚ In Progress (8) â”‚ Resolved (4) â”‚ Retest (2) â”‚ Closed (45)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 DEF-047 S3  â”‚ DEF-001 S1 ğŸ”´â”‚ DEF-002 S3      â”‚ DEF-003 S2   â”‚ DEF-010 S3 â”‚ DEF-009 S4
 DEF-048 S4  â”‚ DEF-015 S2   â”‚ DEF-005 S3      â”‚ DEF-008 S3   â”‚ DEF-022 S2 â”‚ DEF-011 S3
 DEF-049 S3  â”‚ DEF-017 S3   â”‚ DEF-006 S4      â”‚ DEF-012 S3   â”‚            â”‚ ...
             â”‚ DEF-020 S3   â”‚ DEF-007 S2 ğŸŸ¡   â”‚ DEF-014 S4   â”‚            â”‚
             â”‚ DEF-023 S4   â”‚ DEF-016 S3      â”‚              â”‚            â”‚
```

### 6.6 Resolving a Defect

The person who fixes the defect (developer/consultant) fills in the following:

- **Resolution:** Describe what was done
- **Resolution Type:** Select one of the following:
  - `code_fix` â€” Code fix
  - `config_change` â€” Configuration change
  - `data_correction` â€” Data correction
  - `workaround` â€” Temporary workaround
  - `by_design` â€” By design (not a defect)
  - `duplicate` â€” Duplicate of another defect
  - `cannot_reproduce` â€” Cannot reproduce
- **Root Cause:** Optional but recommended:
  - `code_error`, `config_error`, `data_issue`, `spec_gap`, `env_issue`, `user_error`, `design_flaw`

### 6.7 Retest and Closure

1. After the defect is `resolved`, the Test Lead clicks "Send to Retest."
2. The defect transitions to `retest` status.
3. A tester re-runs the related test case.
4. Outcome:
   - **Fix successful** â†’ "Retest Passed" â†’ defect becomes `closed`
   - **Fix unsuccessful** â†’ "Retest Failed" â†’ defect becomes `reopened`, returns to assigned

### 6.8 Defect Linking

You can establish relationships between defects:

| Link Type | Meaning | When? |
|-----------|---------|-------|
| **duplicate_of** | This defect is a copy of another | Same bug reported twice |
| **related_to** | Related but independent | Similar defects in the same area |
| **caused_by** | This defect was caused by another | Side effect of a fix |
| **blocks** | This defect must be resolved before the other can be run | Dependency |

---

## 7. Module T5: Test Dashboard

### 7.1 Dashboard Widgets

The Test Dashboard displays the real-time and trend-based status of the testing process with 10 widgets:

| # | Widget | What It Shows | How to Read It |
|---|--------|--------------|----------------|
| 1 | **Test Execution Progress** | Pass/fail/blocked/not_run by level | Horizontal bar per level â€” green should dominate |
| 2 | **Pass Rate Trend** | Daily pass rate line chart | Upward trend is good |
| 3 | **Defect Open/Close Rate** | Daily opened vs. closed defects | Close line should be above open line |
| 4 | **Defect Funnel** | Newâ†’Assignedâ†’InProgressâ†’Resolvedâ†’Closed | A narrowing funnel is good |
| 5 | **Severity Distribution** | S1/S2/S3/S4 distribution (donut) | S1/S2 share should be low |
| 6 | **Defect Aging** | Age of open defects (0â€“3, 4â€“7, 8â€“14, 15+ days) | Aged defects should be minimal |
| 7 | **Test Coverage Map** | Process area Ã— test level heatmap | No empty/red cells is ideal |
| 8 | **Go/No-Go Scorecard** | 10-criteria checklist | All green â†’ Go-Live ready |
| 9 | **Wave Readiness** | Summary by wave | Each wave's independent status |
| 10 | **Top 10 Open Defects** | Most critical open defects | Immediate action list |

### 7.2 Go/No-Go Scorecard

This is the ultimate output of the entire test management process. It is presented to the Steering Committee and answers the question: "Can we proceed to Go-Live?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GO / NO-GO SCORECARD                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Criterion                              â”‚ Target   â”‚ Status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Unit test pass rate                 â”‚ â‰¥ 95%    â”‚ ğŸŸ¢ 97.5% â”‚
â”‚ 2. SIT pass rate                       â”‚ â‰¥ 95%    â”‚ ğŸŸ¢ 96.1% â”‚
â”‚ 3. UAT Happy Path â€” all pass          â”‚ 100%     â”‚ ğŸŸ¢ 100%  â”‚
â”‚ 4. UAT BPO Sign-off â€” all approved    â”‚ 100%     â”‚ ğŸŸ¡ 85%   â”‚
â”‚ 5. Open S1 (Showstopper) defects      â”‚ = 0      â”‚ ğŸŸ¢ 0     â”‚
â”‚ 6. Open S2 (Critical) defects         â”‚ = 0      â”‚ ğŸ”´ 2     â”‚
â”‚ 7. Open S3 (Major) defects            â”‚ â‰¤ 5      â”‚ ğŸŸ¢ 3     â”‚
â”‚ 8. Regression suite pass rate          â”‚ 100%     â”‚ ğŸŸ¢ 100%  â”‚
â”‚ 9. Performance target achievement      â”‚ â‰¥ 95%    â”‚ ğŸŸ¢ 97%   â”‚
â”‚ 10. All critical defects closed        â”‚ 100%     â”‚ ğŸ”´ 94%   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OVERALL DECISION                       â”‚          â”‚ ğŸ”´ NO-GO â”‚
â”‚ (All criteria must be green)           â”‚          â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

In the example above, 2 criteria are red, so the decision is NO-GO. The S2 defects must be closed and BPO sign-offs must be completed.

### 7.3 Dashboard Export

Dashboard data can be exported in 3 formats:

- **PPTX** â€” for Steering Committee presentations
- **PDF** â€” for archiving
- **XLSX** â€” for detailed analysis

**Path:** T5 â†’ top right â†’ "Export" â†’ select format â†’ "Download"

---

## 8. Module T6: Traceability Matrix

### 8.1 What Does It Show?

The Traceability Matrix displays the entire chain from the Explore Phase to test management in a single table:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Requirementâ”‚ WRICEF/Configâ”‚ Test Cases   â”‚ Last Run     â”‚ Open Defects â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚REQ-001   â”‚ WRICEF-023   â”‚ UT-001 âœ…    â”‚ PASS (02/08) â”‚ 0            â”‚
â”‚          â”‚              â”‚ SIT-015 âœ…   â”‚ PASS (02/09) â”‚ 0            â”‚
â”‚          â”‚              â”‚ UAT-008 âš ï¸   â”‚ FAIL (02/10) â”‚ DEF-003 (S2) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚REQ-002   â”‚ CFG-018      â”‚ UT-002 âœ…    â”‚ PASS (02/07) â”‚ 0            â”‚
â”‚          â”‚              â”‚ â€”            â”‚ â€”            â”‚ â€”            â”‚
â”‚          â”‚              â”‚ âš« SIT missingâ”‚              â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚REQ-003   â”‚ â€”            â”‚ âš« No tests   â”‚ â€”            â”‚ â€”            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Color Codes

- ğŸŸ¢ **Green:** Tested and passed
- ğŸŸ¡ **Yellow:** Tested but issues exist (open defect)
- ğŸ”´ **Red:** Tested and failed
- âš« **Gray:** No test case exists or never been run

### 8.3 Gap Detection

The most important function of the Traceability Matrix is gap detection:

- Requirements with no test cases (like REQ-003 above) are automatically highlighted.
- Missing test cases at specific levels (like REQ-002 SIT) are shown.
- Closing these gaps is the Test Lead's responsibility.

### 8.4 Filtering

The matrix can be filtered along the following dimensions:
- **Process area:** FI, SD, MM, PP, ...
- **Wave:** 1, 2, 3, 4
- **Scope item:** L3 scope item
- **Test level:** Focus on a specific level

### 8.5 Export

The matrix can be exported in Excel and PDF formats. The Excel format is suitable for pivot analysis.

---

## 9. Transitioning from Explore Phase to Testing

### 9.1 Transition Steps

When the Explore Phase is complete, the transition to testing follows these steps:

**Step 1 â€” Create the Test Plan (Test Lead):**
Create the test plan in T1, write the strategy, fill in the environment matrix, and define entry/exit criteria. Submit to the PM for approval.

**Step 2 â€” Plan Test Cycles (Test Lead):**
Create wave-based test cycles in T1. Align the calendar with the Realize phase plan.

**Step 3 â€” Auto-Generate Unit Test Suites (Module Lead):**
T2 â†’ Unit tab â†’ create a suite for each process area â†’ use "Generate from WRICEF" to auto-create unit test cases.

**Step 4 â€” Auto-Generate SIT Suites (Test Lead + Module Lead):**
T2 â†’ SIT tab â†’ create suites by E2E scenario â†’ use "Generate from Process" to auto-create SIT cases.

**Step 5 â€” Prepare UAT Suites (Module Lead + BPO):**
T2 â†’ UAT tab â†’ create a suite for each L3 scope item â†’ use "Generate from Process" to create UAT cases â†’ review Happy Path, Exception, and Negative scenarios with the BPO.

**Step 6 â€” Build Regression Suite (Test Lead):**
T2 â†’ Regression tab â†’ clone critical test cases from SIT/Unit â†’ assign risk levels.

**Step 7 â€” Define Performance Test Cases (Tech Lead):**
T2 â†’ Performance tab â†’ create test cases for critical transactions â†’ define target response times and user counts.

**Step 8 â€” Approve Test Cases (Module Lead / Test Lead):**
T2 â†’ review all draft cases â†’ approve them to `approved` status.

### 9.2 Transition Checklist

| # | Task | Owner | Done? |
|---|------|-------|-------|
| 1 | Test plan created and approved | Test Lead + PM | â˜ |
| 2 | Test cycles planned | Test Lead | â˜ |
| 3 | Unit test cases generated (â‰¥1 per WRICEF/Config) | Module Leads | â˜ |
| 4 | SIT cases generated (per E2E scenario) | Test Lead | â˜ |
| 5 | UAT cases generated (per L3 scope item) | Module Lead + BPO | â˜ |
| 6 | Regression suite built | Test Lead | â˜ |
| 7 | Performance cases defined | Tech Lead | â˜ |
| 8 | All cases in approved status | Test Lead | â˜ |
| 9 | QAS environment ready | Basis/Tech team | â˜ |
| 10 | Test data prepared | Module Leads | â˜ |
| 11 | Cloud ALM sync tested | Test Lead | â˜ |

---

## 10. Cloud ALM Synchronization

### 10.1 What Is Synchronized?

Bidirectional synchronization is available between ProjektCoPilot and SAP Cloud ALM:

| ProjektCoPilot â†’ Cloud ALM | Cloud ALM â†’ ProjektCoPilot |
|---------------------------|---------------------------|
| Test case push | â€” |
| Test step push | â€” |
| Execution result push | â€” |
| Defect push | Defect status update |

### 10.2 How to Use

**Single test case sync:**
T2 â†’ relevant test case â†’ "Push to ALM" button

**Bulk sync:**
T2 â†’ select multiple cases â†’ "Bulk ALM Sync" button

**Defect sync:**
T4 â†’ relevant defect â†’ "Push to ALM" button

**Execution result:**
T3 â†’ when execution is complete â†’ "Push Result to ALM" button

### 10.3 Field Mapping

When a test case is pushed, the following fields are transferred to Cloud ALM:

| ProjektCoPilot Field | Cloud ALM Field |
|---------------------|----------------|
| code | External Reference |
| title | Summary |
| description | Description |
| priority | Priority |
| test_level | Test Type |
| process_area | Process Area Tag |
| steps (action/expected) | Test Steps |

---

## 11. Frequently Asked Questions

**Q: I created a requirement in Explore Phase but I don't see a test case. What should I do?**
A: Test cases are not created automatically â€” you need to use the "Generate from WRICEF" or "Generate from Process" buttons. First create the relevant test suite, then use the generation button.

**Q: How do I know at which level a defect was found?**
A: Each defect has a `test_level` field that is auto-populated when the defect is created. It appears as "Unit," "SIT," "UAT," etc. in the defect detail.

**Q: Is the SLA duration in business days or calendar days?**
A: For S1+P1 and S2+P2, calendar hours (24/7) are used. For S3+P3 and S4+P4, business days are used.

**Q: Who can provide a UAT sign-off?**
A: Only users with the BPO (Business Process Owner) or PM role can provide a UAT sign-off.

**Q: I want to modify a test case but it's in approved status. What should I do?**
A: You cannot directly edit an approved case. Clone it, edit the new version, and approve it. Mark the old case as "deprecated."

**Q: Which cases should I add to the regression suite?**
A: Use a risk-based approach. Core financial processes and critical interfaces should be marked as `critical` risk; changes within the same module as `high` risk. The system automatically identifies affected test cases when a WRICEF/Config item changes.

**Q: Where do I get the target response time for performance testing?**
A: When creating a performance test case, enter the target time in milliseconds in the `perf_target_response_ms` field. Typical targets: <2000ms for dialog transactions; batch jobs are determined per project.

**Q: Is the Go/No-Go scorecard calculated automatically?**
A: Yes. T5 Dashboard â†’ Go/No-Go Scorecard calculates all 10 criteria in real time. Green/red statuses update automatically.

**Q: When a defect is updated in Cloud ALM, does it update in ProjektCoPilot too?**
A: Yes, defect synchronization is bidirectional. When a defect status changes in Cloud ALM, the corresponding defect in ProjektCoPilot is also updated.

**Q: How are test cycles organized when there are multiple waves?**
A: Independent test cycles are created for each wave. For example: "Wave 1 â€” Unit Cycle 1," "Wave 1 â€” SIT Cycle 1," "Wave 2 â€” Unit Cycle 1," etc. All waves are visible in parallel on the test calendar.

---

## 12. Abbreviations and Glossary

| Abbreviation | Description |
|-------------|-------------|
| ALM | Application Lifecycle Management |
| BPO | Business Process Owner |
| Config | Configuration Item |
| DEF | Defect (bug record) |
| DEV | Development environment |
| E2E | End-to-End |
| FS/TS | Functional Specification / Technical Specification |
| O2C | Order to Cash |
| P2P | Procure to Pay |
| PM | Program/Project Manager |
| PRD | Production environment |
| QAS | Quality Assurance System (test environment) |
| R2R | Record to Report |
| REG | Regression Test |
| REQ | Requirement |
| SIT | System Integration Test |
| SLA | Service Level Agreement |
| UAT | User Acceptance Test |
| UT | Unit Test |
| WRICEF | Workflow, Report, Interface, Conversion, Enhancement, Form |

---

*End of Document*

*This guide was prepared based on ProjektCoPilot Test Management System FS/TS v1.0. For technical details, refer to test-management-fs-ts.md.*
