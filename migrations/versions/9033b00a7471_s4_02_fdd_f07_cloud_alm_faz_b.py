"""s4_02_fdd_f07_cloud_alm_faz_b

Revision ID: 9033b00a7471
Revises: 226b03ae7ad1
Create Date: 2026-02-22 22:04:25.434057

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy import inspect as sa_inspect


# revision identifiers, used by Alembic.
revision = '9033b00a7471'
down_revision = '226b03ae7ad1'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###

    # cloud_alm_configs: new table for per-tenant SAP Cloud ALM OAuth2 credentials.
    # db.create_all() may have pre-created this in dev, so guard with has_table check.
    bind = op.get_bind()
    if not sa_inspect(bind).has_table("cloud_alm_configs"):
        op.create_table(
            "cloud_alm_configs",
            sa.Column("id", sa.Integer(), nullable=False),
            sa.Column("tenant_id", sa.Integer(), nullable=False, comment="Owning tenant — one config per tenant enforced by unique constraint"),
            sa.Column("alm_url", sa.String(length=512), nullable=False, comment="Base URL of the SAP Cloud ALM instance"),
            sa.Column("client_id", sa.String(length=255), nullable=False, comment="OAuth2 client ID from SAP BTP service key"),
            sa.Column("encrypted_secret", sa.Text(), nullable=False, comment="Fernet-encrypted OAuth2 client secret — NEVER expose in API responses"),
            sa.Column("token_url", sa.String(length=512), nullable=False, comment="OAuth2 token endpoint"),
            sa.Column("sync_requirements", sa.Boolean(), nullable=False, comment="Enable push/pull of requirements to/from Cloud ALM"),
            sa.Column("sync_test_results", sa.Boolean(), nullable=False, comment="Enable push of test run results to Cloud ALM"),
            sa.Column("is_active", sa.Boolean(), nullable=False, comment="Master switch — if False, all sync operations are skipped"),
            sa.Column("last_test_at", sa.DateTime(timezone=True), nullable=True, comment="Timestamp of the last test-connection call"),
            sa.Column("last_test_status", sa.String(length=16), nullable=True, comment="ok | error | timeout"),
            sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
            sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=False),
            sa.ForeignKeyConstraint(["tenant_id"], ["tenants.id"], name="fk_cloud_alm_configs_tenant_id", ondelete="CASCADE"),
            sa.PrimaryKeyConstraint("id"),
            sa.UniqueConstraint("tenant_id", name="uq_cloud_alm_configs_tenant_id"),
        )
        op.create_index(op.f("ix_cloud_alm_configs_tenant_id"), "cloud_alm_configs", ["tenant_id"], unique=True)

    with op.batch_alter_table("cloud_alm_sync_logs", schema=None) as batch_op:
        batch_op.add_column(sa.Column("http_status_code", sa.Integer(), nullable=True, comment="HTTP status from ALM API"))
        batch_op.add_column(sa.Column("records_pushed", sa.Integer(), nullable=True, comment="Count of records sent to ALM"))
        batch_op.add_column(sa.Column("records_pulled", sa.Integer(), nullable=True, comment="Count of records received from ALM"))
        batch_op.add_column(sa.Column("duration_ms", sa.Integer(), nullable=True, comment="Round-trip latency in milliseconds"))
        batch_op.add_column(sa.Column("triggered_by", sa.String(length=20), nullable=True, comment="manual | scheduled | webhook"))
        batch_op.add_column(sa.Column("user_id", sa.Integer(), nullable=True, comment="User who triggered the sync (FK → users.id)"))
        batch_op.add_column(sa.Column("payload_hash", sa.String(length=64), nullable=True, comment="SHA-256 hex digest of the serialised payload for integrity audit"))
        batch_op.add_column(sa.Column("project_id", sa.Integer(), nullable=True, comment="Program/project scope — enables sync-log listing by project"))
        batch_op.alter_column("requirement_id", existing_type=sa.VARCHAR(length=36), nullable=True)
        batch_op.create_index(batch_op.f("ix_cloud_alm_sync_logs_project_id"), ["project_id"], unique=False)

    # give the pre-existing self-referential FK on explore_requirements a proper name
    with op.batch_alter_table("explore_requirements", schema=None) as batch_op:
        batch_op.create_foreign_key(
            "fk_explore_requirements_parent_self",
            "explore_requirements",
            ["parent_id"],
            ["id"],
            ondelete="SET NULL",
        )

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("explore_requirements", schema=None) as batch_op:
        batch_op.drop_constraint("fk_explore_requirements_parent_self", type_="foreignkey")

    with op.batch_alter_table("cloud_alm_sync_logs", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_cloud_alm_sync_logs_project_id"))
        batch_op.alter_column("requirement_id", existing_type=sa.VARCHAR(length=36), nullable=False)
        batch_op.drop_column("project_id")
        batch_op.drop_column("payload_hash")
        batch_op.drop_column("user_id")
        batch_op.drop_column("triggered_by")
        batch_op.drop_column("duration_ms")
        batch_op.drop_column("records_pulled")
        batch_op.drop_column("records_pushed")
        batch_op.drop_column("http_status_code")

    op.drop_index(op.f("ix_cloud_alm_configs_tenant_id"), table_name="cloud_alm_configs")
    op.drop_table("cloud_alm_configs")

    # ### end Alembic commands ###
