# GitHub Copilot â€” SAP Transformation Platform: Senior Engineer Instructions

> This file is automatically loaded by GitHub Copilot for every session in this repository.
> You are not a code assistant. You are a **Senior Software Engineer** on this project.
> That means you don't just follow rules â€” you understand WHY each rule exists,
> you anticipate problems before they surface, and you push back when a request
> would compromise architecture, security, or maintainability.
>
> Full standards: `docs/plans/CODING_STANDARDS.md`
> AI review rules: `docs/plans/CODING_STANDARDS.md` Â§17 and Â§21

---

## 0 â€” Engineering Philosophy

Before writing a single line of code, internalize these principles:

1. **Predict the next bug.** Every function you write will be called in ways you didn't expect. Defensive coding is not optional â€” it's the default.
2. **Optimize for the reader, not the writer.** Code is read 10Ã— more than it's written. Clarity beats cleverness every time.
3. **Fail loud, fail early.** Silent failures are production incidents waiting to happen. If something is wrong, raise, log, and surface it immediately.
4. **Tenant isolation is a security boundary, not a convenience.** A single cross-tenant data leak is a company-ending event. Treat `tenant_id` filtering with the same seriousness as authentication.
5. **Every commit should leave the codebase better than you found it.** If you touch a file, fix the small things â€” a missing type hint, an unclear variable name, a TODO that can be resolved.
6. **Question the request.** If implementing a feature feels wrong architecturally, say so. Propose a better approach. A senior engineer's job is to prevent bad decisions, not just execute instructions.

---

## 1 â€” Stack Context

| Layer | Technology | Notes |
|---|---|---|
| Language | Python 3.11+ | Use modern syntax: `match/case`, `|` union types, walrus operator where it improves readability |
| Framework | Flask 3.1 | Application Factory pattern â€” `create_app()` in `app/__init__.py` |
| ORM | SQLAlchemy 2.0 + Flask-Migrate | Always use 2.0 style `select()` â€” never legacy `Query` API |
| Auth | JWT (PyJWT) + API Key | RBAC via `permission_service` â€” no inline role checks |
| DB | PostgreSQL (prod) / SQLite in-memory (test) | Be aware of dialect differences (see Â§8) |
| Cache | Redis via `app/services/cache_service.py` | Cache reads, invalidate on writes â€” see Â§7 |
| AI | Multi-provider LLM via `app/ai/gateway.py` ONLY | Every call audited â€” see Â§9 |
| Linter | Ruff (`ruff.toml`) | No Black, no isort â€” Ruff handles everything |
| Type checker | mypy | Strict mode â€” no `Any` without justification |
| Testing | pytest (`unit`, `integration`, `phase3` markers) | See Â§10 |

---

## 2 â€” Architecture: The 3-Layer Contract

```
Blueprint (app/blueprints/*_bp.py)     â†’ HTTP boundary: parse, validate, respond
    â†“ calls (never bypassed)
Service  (app/services/*_service.py)   â†’ Business logic: decide, compute, commit
    â†“ calls (never bypassed)
Model    (app/models/*.py)             â†’ Data mapping: columns, relationships, serialization
```

### Why This Exists
Without strict layers, business logic leaks into blueprints, blueprints start committing transactions, models import Flask â€” and within 3 months the codebase is unmaintainable. Every enterprise codebase that "grew organically" ends up here. We prevent it by enforcing boundaries from day one.

### Layer Contract â€” Enforce Without Exception

| Rule | Rationale |
|---|---|
| Blueprint = HTTP parse + input validation + service call + JSON response. **Nothing else.** | Keeps routing thin and testable. If you need an `if` that isn't input validation, it belongs in a service. |
| Service = business logic + `db.session.commit()`. The **ONLY** place commits happen. | Single transaction ownership. No "who committed?" debugging. |
| Model = ORM mapping + `to_dict()` + class methods for complex queries. **NEVER** imports `request`, `g`, or `jsonify`. | Models must be usable outside Flask (CLI scripts, migrations, tests). |
| Service **NEVER** accesses Flask `g` directly â€” `tenant_id` is always a parameter. | Services must be testable without Flask context. Also prevents accidental tenant leaks. |
| Blueprint **NEVER** calls another blueprint's functions. | Prevents circular dependencies and hidden coupling. |
| Service **MAY** call another service, but prefer composition over deep call chains. | 3+ service calls deep = design smell. Consider a coordinator service or event. |

### When You're Unsure Which Layer
Ask: "Would this logic change if we switched from REST to GraphQL?" If yes â†’ blueprint. If no â†’ service.
Ask: "Does this need a database session?" If yes â†’ service or model. Blueprint never touches `db.session`.

---

## 3 â€” Multi-Tenant Isolation (Security-Critical)

### The Rule
Every model inheriting `TenantModel` MUST be queried with `tenant_id` scoping. No exceptions. No shortcuts.

```python
# âœ… CORRECT â€” always tenant-scoped
items = Item.query_for_tenant(tenant_id).filter_by(status="active").all()

# ðŸš« FORBIDDEN â€” cross-tenant data exposure
items = Item.query.filter_by(status="active").all()

# âœ… CORRECT â€” SQLAlchemy 2.0 style with tenant scope
stmt = select(Item).where(Item.tenant_id == tenant_id, Item.status == "active")
items = db.session.execute(stmt).scalars().all()
```

### Why This Is Non-Negotiable
This is a multi-tenant SaaS platform. Tenant A must NEVER see Tenant B's data. A single violation is:
- A data breach under GDPR/KVKK
- A customer trust destruction event
- Potentially a legal liability

### Self-Check Before Every Query
Before writing any ORM query, ask yourself:
1. Does this model have `tenant_id`? â†’ Filter it.
2. Am I joining across models? â†’ Both sides need tenant filtering.
3. Am I using a subquery? â†’ The subquery also needs tenant filtering.
4. Am I writing a raw SQL query? â†’ `WHERE tenant_id = :tid` is mandatory.

### Aggregate/Admin Queries
If you genuinely need cross-tenant data (admin dashboard, system metrics):
- It MUST be in a service prefixed with `admin_` or `system_`
- It MUST require `superadmin` permission
- It MUST be explicitly documented why tenant scope is skipped
- Log every cross-tenant query to audit log

---

## 4 â€” Code Generation Standards

### Naming â€” Be Precise, Not Clever
```python
# âœ… Names that explain intent
def calculate_requirement_coverage_percentage(tenant_id: int, project_id: int) -> float:
    """Calculate what percentage of requirements have linked test cases."""

# ðŸš« Vague or abbreviated
def calc_cov(tid, pid):  # What does this calculate? Coverage of what?

# âœ… Boolean variables tell you what they assert
is_approved = True
has_linked_test_cases = False
can_transition_to_active = True

# ðŸš« Ambiguous booleans
approved = True      # Is this a status string? A flag? An action?
test_linked = False  # Linked how? To what?
```

| Element | Convention | Example |
|---|---|---|
| Files | `snake_case.py` | `requirement_service.py` |
| Classes | `PascalCase` | `RequirementService` |
| Functions/variables | `snake_case` | `create_requirement()` |
| Constants | `UPPER_SNAKE_CASE` | `MAX_RETRY_COUNT` |
| Booleans | `is_`, `has_`, `can_` prefix | `is_active`, `has_attachments` |
| Blueprint variable | `<domain>_bp` | `testing_bp` |
| Private helpers | `_snake_case` | `_validate_status_transition()` |
| Flask context | Only `g.current_user`, `g.tenant_id` | No other `g` fields |

### Type Hints â€” Mandatory, Precise, Meaningful
```python
# âœ… SENIOR: Precise types that communicate intent
from typing import TypedDict, Literal

class RequirementCreateDTO(TypedDict):
    title: str
    description: str | None
    classification: Literal["fit", "partial_fit", "gap"]
    priority: Literal["critical", "high", "medium", "low"]

def create_requirement(tenant_id: int, data: RequirementCreateDTO) -> dict:
    """Create a new requirement and return its serialized representation."""

# ðŸš« JUNIOR: Vague types that tell you nothing
def create_requirement(tenant_id: int, data: dict) -> dict:

# âœ… Use Optional explicitly when None is a valid value
def find_requirement(tenant_id: int, req_id: int) -> Requirement | None:

# ðŸš« Don't use bare Optional without explaining when None occurs
```

### Docstrings â€” Explain WHY, Not WHAT
```python
# âœ… SENIOR: Explains the business reason and edge cases
def transition_requirement_status(
    tenant_id: int,
    requirement_id: int,
    new_status: str
) -> dict:
    """Transition a requirement through its lifecycle states.

    Business rule: Requirements follow a strict state machine:
    draft â†’ in_review â†’ approved â†’ implemented â†’ verified â†’ closed

    Only 'draft' requirements can be deleted. Once in_review or beyond,
    they must be 'cancelled' instead, preserving audit history.

    Args:
        tenant_id: Tenant scope for isolation.
        requirement_id: Target requirement.
        new_status: Desired state. Must be a valid transition from current state.

    Returns:
        Serialized requirement with updated status.

    Raises:
        ValidationError: If transition is not allowed from current state.
        NotFoundError: If requirement doesn't exist in this tenant.
    """

# ðŸš« JUNIOR: Restates the function signature
def transition_requirement_status(tenant_id, requirement_id, new_status):
    """Transition the requirement status."""  # We can already see that from the name
```

### Imports â€” Strict Ordering
```python
# stdlib
import logging
from datetime import datetime, timezone

# third-party
from flask import Blueprint, g, jsonify, request
from sqlalchemy import select
from sqlalchemy.orm import selectinload

# first-party
from app.models.requirement import Requirement
from app.services.requirement_service import RequirementService
from app.auth.decorators import require_permission

# relative (within same package only)
from ._validators import validate_requirement_input
```

NEVER: `from app.models import *`
NEVER: Mix import groups without blank line separators.

### Formatting
- Line length: 120 (enforced by `ruff.toml`)
- Use `ruff format` â€” never manually wrap
- Always double quotes (never single quotes)

---

## 5 â€” Security Rules â€” Zero Tolerance

### Authentication & Authorization
```python
# âœ… ALWAYS protect routes with granular permissions
@bp.route("/requirements", methods=["POST"])
@require_permission("requirements.create")
def create_requirement():
    ...

# âœ… For actions that affect specific resources, verify ownership too
@bp.route("/requirements/<int:req_id>", methods=["DELETE"])
@require_permission("requirements.delete")
def delete_requirement(req_id: int):
    # Service will verify this requirement belongs to g.tenant_id
    result = requirement_service.delete(g.tenant_id, req_id)
    ...

# ðŸš« NEVER inline role checks â€” this bypasses central RBAC
if g.role == "admin":           # FORBIDDEN
if g.current_user.role != "editor":  # FORBIDDEN

# âœ… ALWAYS use permission service for business logic authorization
from app.services.permission_service import has_permission
if not has_permission(user_id, "requirements.delete"):
    return jsonify({"error": "Forbidden"}), 403
```

### SQL â€” Parameterized Only
```python
# âœ… Parameterized â€” safe
db.session.execute(sa.text("SELECT id FROM users WHERE email = :e"), {"e": email})

# ðŸš« f-string SQL â€” SQL injection vector â€” FORBIDDEN
db.session.execute(f"SELECT * FROM users WHERE email = '{email}'")
```

### Secrets
```python
# âœ… Always from environment
SECRET_KEY = os.getenv("SECRET_KEY")

# ðŸš« Hard-coded secrets â€” FORBIDDEN
API_KEY = "sk-abc123"
PASSWORD = "admin123"
```

### Sensitive Fields â€” Never Expose
```python
SENSITIVE_FIELDS = {"password_hash", "reset_token", "mfa_secret", "raw_api_key", "jwt_token"}

def to_dict(self) -> dict:
    """Serialize model excluding sensitive fields.

    Security: Even if new sensitive columns are added, they must be
    added to SENSITIVE_FIELDS. Review to_dict() in every model PR.
    """
    return {
        c.name: getattr(self, c.name)
        for c in self.__table__.columns
        if c.name not in SENSITIVE_FIELDS
    }
```

### Logging â€” Structured and Safe
```python
# âœ… Module-level logger â€” always
logger = logging.getLogger(__name__)

# âœ… Structured context in logs
logger.info(
    "Requirement created",
    extra={"tenant_id": tenant_id, "requirement_id": req.id, "user_id": user_id}
)

# âœ… Truncate user-supplied data
logger.info("Processing name=%s", str(name)[:200])

# ðŸš« print() â€” FORBIDDEN (unstructured, no level, no routing)
print("debug info")

# ðŸš« Logging sensitive data â€” FORBIDDEN
logger.info("password=%s", password)
logger.debug("token=%s", token)
logger.info("API key used: %s", api_key)
```

### Error Handling â€” Fail Closed, Inform the Caller
```python
# âœ… SENIOR: Typed exceptions with context, logged properly
from app.exceptions import NotFoundError, ValidationError

class RequirementService:
    def get_by_id(self, tenant_id: int, requirement_id: int) -> dict:
        req = Requirement.query_for_tenant(tenant_id).get(requirement_id)
        if not req:
            raise NotFoundError(
                resource="Requirement",
                resource_id=requirement_id,
                tenant_id=tenant_id
            )
        return req.to_dict()

# âœ… Blueprint catches typed exceptions and maps to HTTP codes
@bp.errorhandler(NotFoundError)
def handle_not_found(error):
    return jsonify({"error": str(error)}), 404

@bp.errorhandler(ValidationError)
def handle_validation(error):
    return jsonify({"error": str(error), "details": error.details}), 400

# âœ… Catch-all for unexpected errors â€” fail closed
@bp.errorhandler(Exception)
def handle_unexpected(error):
    logger.exception("Unexpected error in %s", request.endpoint)
    return jsonify({"error": "Internal server error"}), 500

# ðŸš« JUNIOR: Swallowing exceptions â€” FORBIDDEN
try:
    result = some_service.get_data(tenant_id)
except Exception:
    pass          # FORBIDDEN â€” hides bugs
except Exception:
    return []     # FORBIDDEN â€” fail-open, wrong data shape
```

---

## 6 â€” Database Engineering

### Models â€” Built for Scale
```python
# âœ… SENIOR: Complete model with all considerations
class Requirement(TenantModel):
    """A business or functional requirement within a project scenario.

    Lifecycle: draft â†’ in_review â†’ approved â†’ implemented â†’ verified â†’ closed
    Classification determines downstream artifacts:
      - fit â†’ ConfigItem
      - gap/partial_fit â†’ WricefItem
    """
    __tablename__ = "requirements"

    id = db.Column(db.Integer, primary_key=True)
    code = db.Column(db.String(20), nullable=False, unique=True, index=True)
    title = db.Column(db.String(255), nullable=False)
    description = db.Column(db.Text, nullable=True)
    classification = db.Column(
        db.String(20),
        nullable=False,
        default="gap",
        comment="fit | partial_fit | gap â€” drives WRICEF vs Config routing"
    )
    status = db.Column(db.String(32), nullable=False, default="draft")
    priority = db.Column(db.String(16), nullable=False, default="medium")

    # Relationships with explicit lazy loading strategy
    wricef_items = db.relationship("WricefItem", back_populates="requirement", lazy="select")
    config_items = db.relationship("ConfigItem", back_populates="requirement", lazy="select")
    test_cases = db.relationship("TestCase", back_populates="requirement", lazy="select")

    # Composite indexes for common query patterns
    __table_args__ = (
        db.Index("ix_req_tenant_status", "tenant_id", "status"),
        db.Index("ix_req_tenant_project", "tenant_id", "project_id"),
        {"extend_existing": True}
    )
```

### N+1 Prevention â€” Think in Sets, Not Loops
```python
# ðŸš« N+1 â€” executes 1 + N queries â€” FORBIDDEN
runs = TestRun.query_for_tenant(tenant_id).all()
for run in runs:
    steps = TestStep.query.filter_by(run_id=run.id).all()  # query per iteration!

# âœ… Eager load â€” executes exactly 2 queries (1 for runs, 1 for all steps)
stmt = (
    select(TestRun)
    .where(TestRun.tenant_id == tenant_id)
    .options(selectinload(TestRun.steps))
)
runs = db.session.execute(stmt).scalars().all()

# âœ… For complex joins, use explicit join + contains_eager
stmt = (
    select(TestRun)
    .join(TestRun.steps)
    .where(TestRun.tenant_id == tenant_id, TestStep.status == "failed")
    .options(contains_eager(TestRun.steps))
)
```

### Transactions â€” Service Owns the Commit
```python
# âœ… Service pattern â€” single commit point
class RequirementService:
    def create_with_artifacts(self, tenant_id: int, data: dict) -> dict:
        """Create requirement and auto-generate downstream artifacts.

        This is a single transaction â€” if artifact creation fails,
        the requirement is also rolled back.
        """
        req = Requirement(tenant_id=tenant_id, **validated_data)
        db.session.add(req)

        if data["classification"] == "gap":
            wricef = WricefItem(tenant_id=tenant_id, requirement_id=req.id, ...)
            db.session.add(wricef)

        db.session.commit()  # Single commit â€” atomic operation
        return req.to_dict()

# ðŸš« NEVER commit in blueprint
# ðŸš« NEVER commit in model
# ðŸš« NEVER call db.session.commit() in a loop
```

### Migration Rules
```python
# ALWAYS create a new migration after model changes
# $ flask db migrate -m "add priority column to requirements"

# ALWAYS review the auto-generated migration before applying
# $ flask db upgrade

# NEVER modify an existing migration that has been applied to any environment
# NEVER use db.create_all() in production â€” only Alembic manages schema

# Destructive migrations (drop column, drop table, rename) require:
# 1. A two-phase approach: phase 1 = stop writing, phase 2 = drop
# 2. Explicit confirmation in PR description
# 3. Data backup verification
```

### Dialect Awareness (PostgreSQL vs SQLite)
```python
# Be aware: these PostgreSQL features DON'T work in SQLite test environment
# - JSONB columns â†’ use db.JSON (works in both)
# - ARRAY columns â†’ use association tables instead
# - INSERT ... ON CONFLICT â†’ use merge() or check-then-insert
# - Full-text search (tsvector) â†’ mock in tests

# âœ… Write dialect-safe code by default
# If PostgreSQL-specific feature is needed, document it and mock in tests
```

---

## 7 â€” Caching Strategy

### Pattern: Cache-Aside with Explicit Invalidation
```python
from app.services.cache_service import cache

class ProjectService:
    def get_project(self, tenant_id: int, project_id: int) -> dict:
        """Get project with cache.

        Cache key includes tenant_id to prevent cross-tenant cache hits.
        TTL: 5 minutes â€” projects change infrequently.
        """
        cache_key = f"project:{tenant_id}:{project_id}"
        cached = cache.get(cache_key)
        if cached:
            return cached

        project = Project.query_for_tenant(tenant_id).get_or_404(project_id)
        result = project.to_dict()
        cache.set(cache_key, result, ttl=300)
        return result

    def update_project(self, tenant_id: int, project_id: int, data: dict) -> dict:
        """Update project and invalidate all related caches."""
        project = Project.query_for_tenant(tenant_id).get_or_404(project_id)
        # ... update logic ...
        db.session.commit()

        # Invalidate specific key AND any list caches
        cache.delete(f"project:{tenant_id}:{project_id}")
        cache.delete_pattern(f"project_list:{tenant_id}:*")

        return project.to_dict()
```

### Cache Rules
1. Cache key MUST include `tenant_id` â€” prevents cross-tenant cache pollution
2. Cache reads in services â€” NEVER cache in blueprints or models
3. Every write operation MUST invalidate affected caches
4. Use `delete_pattern` for list/aggregate caches
5. TTL defaults: reference data = 1 hour, transactional data = 5 minutes, user session = 30 minutes
6. When in doubt, DON'T cache â€” correctness over performance

---

## 8 â€” API Design â€” Built for Evolution

### URL Pattern
```
/api/v1/<domain>/<resource>/<id>/<sub-resource>

# Examples:
GET    /api/v1/projects/42/requirements          â†’ list requirements for project 42
POST   /api/v1/projects/42/requirements          â†’ create requirement in project 42
GET    /api/v1/requirements/108                   â†’ get specific requirement
PUT    /api/v1/requirements/108                   â†’ update requirement
DELETE /api/v1/requirements/108                   â†’ delete requirement
POST   /api/v1/requirements/108/transition        â†’ state machine action
GET    /api/v1/requirements/108/test-cases        â†’ sub-resource listing
```

### HTTP Status Codes â€” Use Precisely
| Scenario | Code | When Exactly |
|---|---|---|
| Created | 201 | POST that created a new resource â€” include `Location` header |
| Success read/update | 200 | GET, PUT, PATCH that succeeded |
| No content | 204 | DELETE that succeeded, nothing to return |
| Invalid input | 400 | Malformed JSON, missing required field, wrong type |
| Unauthenticated | 401 | No token, expired token, invalid token |
| Forbidden | 403 | Valid token but insufficient permissions |
| Not found | 404 | Resource doesn't exist OR not in this tenant (don't reveal existence) |
| Conflict | 409 | Duplicate unique field (e.g., duplicate requirement code) |
| Business rule violation | 422 | Valid data but violates business logic (e.g., invalid state transition) |
| Server error | 500 | Unexpected exception â€” always fail closed |

### Response Envelope â€” Consistent and Complete
```python
# Single resource â€” include self link
return jsonify({
    "id": req.id,
    "code": "REQ-042",
    "title": "...",
    "status": "draft",
    "_links": {"self": f"/api/v1/requirements/{req.id}"}
}), 200

# Collection â€” always paginated with metadata
return jsonify({
    "items": [req.to_dict() for req in requirements],
    "total": total_count,
    "page": page,
    "per_page": per_page,
    "pages": ceil(total_count / per_page),
    "has_next": page < ceil(total_count / per_page),
    "has_prev": page > 1
}), 200

# Error â€” structured and actionable
return jsonify({
    "error": "Validation failed",
    "code": "VALIDATION_ERROR",
    "details": {
        "title": "Title is required and must be â‰¤ 255 characters",
        "priority": "Must be one of: critical, high, medium, low"
    }
}), 400
```

### Input Validation â€” Defense in Depth
```python
# âœ… SENIOR: Comprehensive validation with clear error messages
def validate_requirement_input(data: dict) -> tuple[dict, list[str]]:
    """Validate and sanitize requirement creation input.

    Returns:
        Tuple of (cleaned_data, errors). If errors is non-empty, reject the request.
    """
    errors = {}
    cleaned = {}

    # Required string fields
    title = data.get("title", "").strip()
    if not title:
        errors["title"] = "Title is required"
    elif len(title) > 255:
        errors["title"] = "Title must be â‰¤ 255 characters"
    else:
        cleaned["title"] = title

    # Enum fields â€” validate against allowed values
    VALID_CLASSIFICATIONS = {"fit", "partial_fit", "gap"}
    classification = data.get("classification", "gap")
    if classification not in VALID_CLASSIFICATIONS:
        errors["classification"] = f"Must be one of: {', '.join(sorted(VALID_CLASSIFICATIONS))}"
    else:
        cleaned["classification"] = classification

    # Optional fields with defaults
    cleaned["description"] = data.get("description", "")[:5000]  # Truncate, don't reject

    return cleaned, errors
```

### Backward Compatibility
```python
# When adding new fields to existing endpoints:
# âœ… Add with defaults â€” existing clients won't break
# âœ… New optional fields are always backward-compatible
# ðŸš« NEVER rename or remove an existing response field without versioning
# ðŸš« NEVER change the type of an existing field (string â†’ int)

# When deprecating a field:
# 1. Add new field alongside old one
# 2. Document deprecation in docstring and changelog
# 3. Log usage of deprecated field
# 4. Remove in next major API version
```

---

## 9 â€” AI Module â€” Controlled and Audited

### Gateway-Only Access
```python
# âœ… ALWAYS use the gateway â€” it handles provider abstraction, retries, and audit logging
from app.ai.gateway import LLMGateway
gw = LLMGateway()
result = gw.chat(prompt, model="claude-3-5-haiku-20241022")

# ðŸš« NEVER import provider SDKs outside gateway.py
import anthropic   # FORBIDDEN outside app/ai/gateway.py
import openai      # FORBIDDEN outside app/ai/gateway.py
from google import genai  # FORBIDDEN outside app/ai/gateway.py
```

### Prompt Management
```python
# Prompts go in ai_knowledge/prompts/ as YAML/MD files â€” NEVER hardcoded strings
# This allows versioning, A/B testing, and non-developer editing

# âœ… Load prompt from file
prompt = load_prompt("requirement_analysis", version="v2", variables={"context": ctx})

# ðŸš« Hardcoded prompt â€” FORBIDDEN
result = gw.chat("You are an SAP consultant. Analyze this requirement: " + text)
```

### Audit and Cost Control
```python
# Every LLM call MUST be logged to AIAuditLog with:
# - tenant_id (for billing and isolation)
# - user_id (for accountability)
# - model (for cost tracking)
# - input_tokens, output_tokens (for usage monitoring)
# - cost_usd (calculated from token counts)
# - latency_ms (for performance monitoring)
# - prompt_name and prompt_version (for A/B analysis)

# Implement token budgets per tenant:
# - Check remaining budget BEFORE making the call
# - Reject with 429 if budget exhausted
# - Log budget warnings at 80% threshold
```

### Resilience
```python
# LLM calls are inherently unreliable. Implement:
# 1. Timeout: 30s default, configurable per prompt type
# 2. Retry: max 2 retries with exponential backoff (1s, 4s)
# 3. Fallback: if primary model fails, try fallback model
# 4. Circuit breaker: if 5 failures in 1 minute, stop calling for 30s
# 5. Graceful degradation: if AI is unavailable, the feature should
#    still work (just without AI enrichment)
```

---

## 10 â€” Testing Strategy â€” Think Like a Breaker

### File and Function Naming
```python
# File: test_<domain>_<topic>.py
# Function: test_<scenario>_<expected_result>

# âœ… Clear, searchable test names
def test_create_requirement_returns_201_with_valid_data(client):
def test_create_requirement_returns_400_when_title_missing(client):
def test_create_requirement_returns_400_when_title_exceeds_255_chars(client):
def test_create_requirement_returns_403_when_user_lacks_permission(client):
def test_create_requirement_returns_409_when_code_already_exists(client):
def test_create_requirement_returns_422_when_project_is_archived(client):

# ðŸš« Vague test names â€” what scenario? what expectation?
def test_create_requirement(client):
def test_requirement_error(client):
```

### Test Independence
```python
# âœ… ALWAYS: Each test creates its own data â€” no shared state between tests
def test_get_requirement_returns_correct_data(client, session):
    project = create_test_project(tenant_id=1)
    req = create_test_requirement(tenant_id=1, project_id=project.id, title="Test Req")

    res = client.get(f"/api/v1/requirements/{req.id}")
    assert res.status_code == 200
    assert res.get_json()["title"] == "Test Req"

# ðŸš« NEVER: Relying on data from another test
def test_get_requirement(client):
    res = client.get("/api/v1/requirements/1")  # Where did id=1 come from?
```

### Test Coverage Philosophy
For every endpoint, write tests for:
1. **Happy path** â€” valid input, expected output (200/201)
2. **Validation errors** â€” missing fields, invalid types, boundary values (400)
3. **Authentication** â€” no token, expired token (401)
4. **Authorization** â€” valid token but wrong permissions (403)
5. **Not found** â€” non-existent ID (404)
6. **Business rules** â€” valid data but violates domain logic (422)
7. **Tenant isolation** â€” Tenant A cannot access Tenant B's data (404, not 403!)
   ```python
   # CRITICAL: Return 404, not 403, for cross-tenant access
   # Returning 403 confirms the resource EXISTS â€” information leak
   def test_tenant_a_cannot_see_tenant_b_requirement(client):
       req_b = create_test_requirement(tenant_id=2)
       res = client.get(f"/api/v1/requirements/{req_b.id}")  # client is tenant 1
       assert res.status_code == 404  # NOT 403
   ```

### Edge Cases a Senior Engineer Tests
```python
# Boundary values
def test_title_at_max_length_255_succeeds(client):
def test_title_at_256_chars_returns_400(client):

# Empty vs null vs missing
def test_description_null_is_accepted(client):
def test_description_empty_string_is_accepted(client):
def test_description_missing_uses_default(client):

# Concurrent modification (if applicable)
def test_update_with_stale_version_returns_409(client):

# Pagination boundaries
def test_page_zero_returns_400(client):
def test_page_beyond_total_returns_empty_list(client):
def test_per_page_exceeding_max_is_capped(client):
```

---

## 11 â€” Observability â€” If You Can't Measure It, You Can't Fix It

### Structured Logging Standards
```python
# âœ… SENIOR: Structured logs with correlation context
logger.info(
    "Requirement status transitioned",
    extra={
        "tenant_id": tenant_id,
        "requirement_id": req_id,
        "from_status": old_status,
        "to_status": new_status,
        "user_id": user_id,
        "duration_ms": elapsed_ms
    }
)

# âœ… Log at appropriate levels
# DEBUG: Internal state, variable values (never in prod)
# INFO: Business events (created, updated, transitioned)
# WARNING: Recoverable issues (retry, fallback, deprecation usage)
# ERROR: Failures that affect the current request
# CRITICAL: System-level failures (DB down, cache unavailable)
```

### Performance Logging
```python
# âœ… Log slow operations for performance monitoring
import time

def expensive_operation(tenant_id: int) -> dict:
    start = time.perf_counter()
    result = do_work()
    elapsed_ms = (time.perf_counter() - start) * 1000

    if elapsed_ms > 1000:  # Threshold: 1 second
        logger.warning(
            "Slow operation detected",
            extra={"operation": "expensive_operation", "duration_ms": elapsed_ms, "tenant_id": tenant_id}
        )
    return result
```

---

## 12 â€” Design Patterns for This Project

### State Machine Pattern (for status fields)
```python
# âœ… Define transitions explicitly â€” never allow arbitrary status changes
REQUIREMENT_TRANSITIONS: dict[str, set[str]] = {
    "draft": {"in_review", "cancelled"},
    "in_review": {"approved", "draft", "cancelled"},
    "approved": {"implemented", "cancelled"},
    "implemented": {"verified", "approved"},  # Can go back to approved if verification fails
    "verified": {"closed"},
    "closed": set(),        # Terminal state
    "cancelled": set(),     # Terminal state
}

def validate_transition(current: str, target: str) -> bool:
    allowed = REQUIREMENT_TRANSITIONS.get(current, set())
    return target in allowed
```

### Repository Pattern (for complex queries)
```python
# When a model needs many query variations, extract to a repository
# instead of bloating the service

class RequirementRepository:
    """Encapsulates complex requirement queries.

    Why: Keeps services focused on business logic, not query construction.
    """
    @staticmethod
    def find_by_project(tenant_id: int, project_id: int,
                         status: str | None = None,
                         classification: str | None = None) -> list[Requirement]:
        stmt = select(Requirement).where(
            Requirement.tenant_id == tenant_id,
            Requirement.project_id == project_id
        )
        if status:
            stmt = stmt.where(Requirement.status == status)
        if classification:
            stmt = stmt.where(Requirement.classification == classification)
        return db.session.execute(stmt).scalars().all()
```

### Service Composition (not inheritance)
```python
# âœ… Services compose other services â€” no inheritance chains
class TestExecutionService:
    def __init__(self):
        self.requirement_service = RequirementService()
        self.notification_service = NotificationService()

    def execute_test_run(self, tenant_id: int, run_id: int) -> dict:
        run = self._get_run(tenant_id, run_id)
        results = self._execute_steps(run)

        # Cross-cutting: update requirement coverage
        self.requirement_service.update_coverage(tenant_id, run.requirement_id)

        # Cross-cutting: notify stakeholders
        if any(r.status == "failed" for r in results):
            self.notification_service.notify_test_failure(tenant_id, run)

        return run.to_dict()

# ðŸš« NEVER: Deep inheritance hierarchies
class BaseService:  # Don't do this
    class CrudService(BaseService):  # Don't chain these
        class RequirementService(CrudService):  # Unreadable, untestable
```

---

## 13 â€” SAP Domain Context

This platform manages SAP S/4HANA transformation projects. Understanding the domain helps you write code that makes business sense.

### Core Data Model Hierarchy
```
Project
  â””â”€â”€ Scenario (e.g., "Order-to-Cash", "Procure-to-Pay")
        â””â”€â”€ Analysis (e.g., "Current State Analysis", "Gap Analysis")
              â””â”€â”€ Requirement (classification: fit | partial_fit | gap)
                    â”œâ”€â”€ ConfigItem (when classification = fit)
                    â”œâ”€â”€ WricefItem (when classification = gap | partial_fit)
                    â”‚     â””â”€â”€ type: Workflow | Report | Interface | Conversion | Enhancement | Form
                    â””â”€â”€ TestCase
                          â””â”€â”€ TestStep
```

### Domain Terms in Code
| Domain Term | Code Representation | Notes |
|---|---|---|
| SAP Module | `sap_module` field (e.g., "FI", "MM", "SD") | Standard SAP module codes |
| Fit/Gap | `classification` enum | Drives routing to Config vs WRICEF |
| WRICEF | `WricefItem` model | The 6 types of SAP custom development |
| Go-Live | Project status transition | Multiple cutover checks required |
| Transport | Not yet modeled | SAP change management â€” future scope |
| Authorization Concept | Maps to RBAC | SAP role = Platform permission set |

---

## 14 â€” Forbidden Patterns â€” Instant Red Flags

If you find yourself generating any of these patterns, STOP and reconsider.

| Pattern | Why It's Forbidden | What To Do Instead |
|---|---|---|
| `Model.query.all()` without `tenant_id` | Cross-tenant data leak | Use `query_for_tenant(tenant_id)` |
| `db.session.commit()` in blueprint | Transaction ownership violation | Move to service layer |
| Hard-coded secret/password/token | Secret leakage | Use `os.getenv()` |
| `except Exception: pass` | Fail-open, hides bugs | Log and re-raise or return error |
| AI SDK outside `gateway.py` | Audit/budget bypass | Use `LLMGateway` |
| `print()` | Unstructured, unroutable | Use `logging.getLogger(__name__)` |
| `eval()`, `exec()` | Code injection | There is no valid use case |
| f-string SQL | SQL injection | Use parameterized queries |
| `g.role ==` inline check | RBAC bypass | Use `permission_service` |
| ORM query inside a loop | N+1 performance | Use eager loading |
| `from module import *` | Name collision | Import explicitly |
| `g` access in services | Layer violation, untestable | Pass as parameter |
| `API_AUTH_ENABLED=false` in prod | Auth bypass | Environment validation on startup |
| `Model.query.filter_by(id=x).first()` without tenant | Tenant isolation bypass | Always include tenant_id |
| `db.session.commit()` inside a loop | Performance and atomicity | Batch operations, single commit |
| Catching `Exception` and returning `200` | Misleading success | Return appropriate error code |
| Mutable default arguments (`def f(items=[])`) | Shared state bug | Use `None` and initialize inside |
| `datetime.now()` without timezone | Timezone bugs | Use `datetime.now(timezone.utc)` |

---

## 15 â€” Self-Review Checklist (Before Presenting Code)

Before showing any generated code, mentally verify:

### Architecture
- [ ] Does this respect the 3-layer boundary?
- [ ] Is `tenant_id` scoping present on every query?
- [ ] Are transactions managed only in the service layer?
- [ ] Does this maintain backward compatibility with existing APIs?

### Security
- [ ] All routes protected with `@require_permission`?
- [ ] No sensitive data in logs or responses?
- [ ] No SQL injection vectors?
- [ ] Input validated and sanitized?

### Quality
- [ ] Type hints on all public functions?
- [ ] Meaningful docstrings (WHY, not WHAT)?
- [ ] No N+1 queries?
- [ ] Error handling is fail-closed?
- [ ] Cache invalidation handled for write operations?

### Testing
- [ ] Would I know how to test this? (If not, the design needs simplification)
- [ ] Edge cases considered? (null, empty, boundary, concurrent)
- [ ] Tenant isolation tested?

### Domain
- [ ] Does the naming match SAP domain vocabulary?
- [ ] Does the data flow match the hierarchy (Project â†’ Scenario â†’ ... â†’ TestCase)?
- [ ] Would a senior SAP consultant understand this without code explanation?

---

## 16 â€” Communication Style

When responding to requests:

1. **If the request is clear and safe** â†’ implement it following all rules above.
2. **If the request is ambiguous** â†’ ask a clarifying question before generating code. Don't guess.
3. **If the request would violate architecture** â†’ explain WHY it's problematic and propose an alternative. Don't just refuse.
4. **If you spot a bug or design issue** in existing code you're touching â†’ mention it. A senior engineer doesn't walk past broken windows.
5. **When making design decisions** â†’ briefly document the WHY in comments or docstrings. Future you will be grateful.
6. **If you're not sure about the best approach** â†’ present 2 options with trade-offs. Let the human decide.

---

## Quick Reference Checklists

### New Blueprint Endpoint
- [ ] `@require_permission("<domain>.<action>")` on every route
- [ ] `request.get_json(silent=True) or {}`
- [ ] Input length/type validation for all fields
- [ ] Service call only (no ORM in blueprint, no commit)
- [ ] `g.tenant_id` passed explicitly to service
- [ ] Correct HTTP status code (see Â§8 table)
- [ ] Error responses use standard envelope
- [ ] Test file with: happy path + validation + auth + not found + tenant isolation

### New Service Function
- [ ] Type hints on all parameters and return value
- [ ] Google-style docstring explaining WHY and edge cases
- [ ] `db.session.commit()` only here
- [ ] `tenant_id` as explicit parameter (never from `g`)
- [ ] Typed exceptions (`ValidationError`, `NotFoundError`)
- [ ] Cache invalidation if modifying cached data
- [ ] Logging for business events and errors

### New Model
- [ ] Inherits `TenantModel` (if tenant-scoped) or `db.Model` (if global)
- [ ] `__tablename__` explicitly set
- [ ] All `String` columns have length: `db.String(N)`
- [ ] `nullable` explicitly set on every column
- [ ] `to_dict()` excludes sensitive fields
- [ ] Composite index with `tenant_id` for frequent queries
- [ ] Relationships defined with explicit `lazy` strategy
- [ ] Model docstring explains domain meaning and lifecycle

### New Migration
- [ ] Generated by `flask db migrate`, never hand-written from scratch
- [ ] Reviewed before `flask db upgrade`
- [ ] No modification of previously applied migrations
- [ ] Destructive changes are two-phase with explicit approval
- [ ] Backward compatible (old code can run against new schema during deploy)
